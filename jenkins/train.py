# jenkins/train.py - Version avec TensorBoard corrigÃ©e
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import joblib
import os
import time

# TensorBoard - avec gestion d'erreur au cas oÃ¹ PyTorch n'est pas installÃ©
try:
    from torch.utils.tensorboard import SummaryWriter
    TENSORBOARD_AVAILABLE = True
    print("âœ… TensorBoard disponible")
except ImportError:
    TENSORBOARD_AVAILABLE = False
    print("âš ï¸ TensorBoard non disponible (PyTorch non installÃ©)")

# 1. Chargement des donnÃ©es
iris = pd.read_csv("data/Iris.csv")

print("ğŸ“Š Dataset original:")
print(f"Shape: {iris.shape}")
print(f"Colonnes: {list(iris.columns)}")

# 2. Supprimer TOUTES les colonnes non-features (Id, index, etc.)
feature_columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']
target_column = 'Species'

missing_cols = []
for col in feature_columns + [target_column]:
    if col not in iris.columns:
        missing_cols.append(col)

if missing_cols:
    print(f"âŒ Colonnes manquantes: {missing_cols}")
    print("Colonnes disponibles:", list(iris.columns))
    exit(1)

# 3. SÃ©lection exacte des features
X = iris[feature_columns].copy()
y = iris[target_column].copy()

print(f"\nâœ… Features sÃ©lectionnÃ©es: {X.shape}")
print(f"Features: {list(X.columns)}")
print(f"Target: {y.name}")

# 4. Configuration TensorBoard - CHEMIN CORRIGÃ‰
writer = None
if TENSORBOARD_AVAILABLE:
    # DÃ©terminer le rÃ©pertoire racine du projet
    current_dir = os.getcwd()
    if current_dir.endswith('jenkins'):
        # Si on est dans jenkins/, remonter d'un niveau
        root_dir = os.path.dirname(current_dir)
    else:
        # Sinon on est dÃ©jÃ  Ã  la racine
        root_dir = current_dir
    
    # Chemin absolu vers TensorBoard
    tensorboard_path = os.path.join(root_dir, "artifacts", "tensorboard")
    os.makedirs(tensorboard_path, exist_ok=True)
    
    print(f"ğŸ“ RÃ©pertoire de travail: {current_dir}")
    print(f"ğŸ“ RÃ©pertoire racine: {root_dir}")
    print(f"ğŸ“ Chemin TensorBoard: {tensorboard_path}")
    
    # VÃ©rifier que le dossier existe
    if os.path.exists(tensorboard_path):
        writer = SummaryWriter(tensorboard_path)
        print(f"ğŸ“Š TensorBoard writer crÃ©Ã© avec succÃ¨s")
        
        # Log du dataset
        writer.add_scalar("Dataset/nb_samples", len(X), 0)
        writer.add_scalar("Dataset/nb_features", len(feature_columns), 0)
        writer.add_scalar("Dataset/nb_classes", y.nunique(), 0)
        print(f"ğŸ“Š Logs TensorBoard dans: {tensorboard_path}")
    else:
        print(f"âŒ Impossible de crÃ©er le dossier TensorBoard: {tensorboard_path}")
        TENSORBOARD_AVAILABLE = False

# 5. VÃ©rification des donnÃ©es
print(f"\nDonnÃ©es X shape: {X.shape}")
print(f"DonnÃ©es y shape: {y.shape}")
print(f"Classes uniques: {y.unique()}")

# 6. Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print(f"\nğŸ“Š Split:")
print(f"Train: {X_train.shape}")
print(f"Test: {X_test.shape}")

# 7. EntraÃ®nement du modÃ¨le
print("\nğŸš€ EntraÃ®nement du modÃ¨le SVM...")
start_time = time.time()
model = SVC(probability=True, random_state=42)
model.fit(X_train, y_train)
train_time = time.time() - start_time

print(f"â±ï¸ Temps d'entraÃ®nement: {train_time:.2f}s")

# Log TensorBoard du temps d'entraÃ®nement
if writer:
    writer.add_scalar("Training/time_seconds", train_time, 0)
    print("ğŸ“Š Temps d'entraÃ®nement loggÃ©")

# 8. PrÃ©diction et Ã©valuation
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nâœ… Accuracy: {accuracy:.3f}")

# Log TensorBoard de l'accuracy
if writer:
    writer.add_scalar("Performance/accuracy", accuracy, 0)
    print("ğŸ“Š Accuracy loggÃ©e")

# 9. MÃ©triques dÃ©taillÃ©es par classe
from sklearn.metrics import classification_report, confusion_matrix
print(f"\nğŸ“Š Rapport de classification:")
report = classification_report(y_test, y_pred, output_dict=True)
print(classification_report(y_test, y_pred))

# Log TensorBoard des mÃ©triques par classe
if writer:
    for class_name, metrics in report.items():
        if isinstance(metrics, dict) and 'precision' in metrics:
            writer.add_scalar(f"Class_{class_name}/precision", metrics['precision'], 0)
            writer.add_scalar(f"Class_{class_name}/recall", metrics['recall'], 0)
            writer.add_scalar(f"Class_{class_name}/f1-score", metrics['f1-score'], 0)
    print("ğŸ“Š MÃ©triques par classe loggÃ©es")

# 10. Matrice de confusion
print(f"\nğŸ“Š Matrice de confusion:")
cm = confusion_matrix(y_test, y_pred)
print(cm)

# Ajouter la matrice de confusion Ã  TensorBoard comme image
if writer:
    import matplotlib.pyplot as plt
    import numpy as np
    
    try:
        fig, ax = plt.subplots(figsize=(8, 6))
        im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
        ax.figure.colorbar(im, ax=ax)
        
        # Ã‰tiquettes
        classes = model.classes_
        ax.set(xticks=np.arange(cm.shape[1]),
               yticks=np.arange(cm.shape[0]),
               xticklabels=classes,
               yticklabels=classes,
               title='Matrice de Confusion',
               ylabel='Vraie classe',
               xlabel='Classe prÃ©dite')
        
        # Ajouter les valeurs dans les cellules
        thresh = cm.max() / 2.
        for i in range(cm.shape[0]):
            for j in range(cm.shape[1]):
                ax.text(j, i, format(cm[i, j], 'd'),
                       ha="center", va="center",
                       color="white" if cm[i, j] > thresh else "black")
        
        fig.tight_layout()
        
        # Sauvegarder et ajouter Ã  TensorBoard
        writer.add_figure("Confusion_Matrix/test_set", fig, 0)
        plt.close(fig)
        print("ğŸ“Š Matrice de confusion ajoutÃ©e Ã  TensorBoard")
    except Exception as e:
        print(f"âš ï¸ Impossible d'ajouter la matrice de confusion: {e}")

# 11. VÃ©rification finale du modÃ¨le
print(f"\nğŸ” ModÃ¨le entraÃ®nÃ©:")
print(f"Features attendues: {model.n_features_in_}")
print(f"Feature names: {getattr(model, 'feature_names_in_', 'Non disponible')}")
print(f"Classes: {model.classes_}")

# 12. Test rapide
test_data = X_test.iloc[0:1]
print(f"\nğŸ§ª Test avec une prÃ©diction:")
print(f"Input shape: {test_data.shape}")
print(f"Input: {test_data.values}")
pred = model.predict(test_data)
proba = model.predict_proba(test_data).max()
print(f"PrÃ©diction: {pred[0]}")
print(f"Confiance: {proba:.3f}")

# Log TensorBoard du test
if writer:
    writer.add_text("Example/prediction", f"{pred[0]} (confiance={proba:.3f})", 0)
    print("ğŸ“Š Exemple de prÃ©diction loggÃ©")

# 13. Histogrammes des features
if writer:
    try:
        # Ajouter des histogrammes des features
        for i, feature in enumerate(feature_columns):
            writer.add_histogram(f"Features/{feature}", X[feature].values, 0)
        print("ğŸ“Š Histogrammes des features ajoutÃ©s")
    except Exception as e:
        print(f"âš ï¸ Impossible d'ajouter les histogrammes: {e}")

# 14. Sauvegarde du modÃ¨le (dans le dossier courant jenkins/)
joblib.dump(model, "iris_model.pkl")
print(f"\nğŸ’¾ ModÃ¨le sauvegardÃ©: iris_model.pkl")

# 15. Sauvegarder les informations des features
feature_info = {
    'feature_names': feature_columns,
    'n_features': len(feature_columns),
    'classes': list(model.classes_)
}
joblib.dump(feature_info, "feature_info.pkl")
print("ğŸ’¾ Info features sauvegardÃ©es: feature_info.pkl")

# 16. Fermer TensorBoard et forcer l'Ã©criture
if writer:
    # Forcer l'Ã©criture des donnÃ©es
    writer.flush()
    writer.close()
    print("ğŸ“Š TensorBoard fermÃ© et donnÃ©es Ã©crites")
    
    # VÃ©rifier que les fichiers ont Ã©tÃ© crÃ©Ã©s
    tensorboard_files = []
    if os.path.exists(tensorboard_path):
        for root, dirs, files in os.walk(tensorboard_path):
            for file in files:
                if file.startswith('events.out.tfevents'):
                    tensorboard_files.append(os.path.join(root, file))
    
    if tensorboard_files:
        print(f"âœ… Fichiers TensorBoard crÃ©Ã©s: {len(tensorboard_files)}")
        for f in tensorboard_files:
            size = os.path.getsize(f)
            print(f"   - {f} ({size} bytes)")
    else:
        print("âŒ Aucun fichier TensorBoard trouvÃ©!")

# 17. Instructions finales
print("\n" + "="*60)
print("ğŸ¯ RÃ‰SULTATS DE L'ENTRAÃNEMENT")
print("="*60)
print(f"âœ… ModÃ¨le: SVM avec accuracy {accuracy:.3f}")
print(f"âœ… Temps d'entraÃ®nement: {train_time:.2f}s")
print(f"âœ… Features: {len(feature_columns)}")
print(f"âœ… Classes: {len(model.classes_)}")

if TENSORBOARD_AVAILABLE and writer:
    print(f"âœ… Logs TensorBoard sauvegardÃ©s")
    print("\nğŸ“Š POUR LANCER TENSORBOARD:")
    print("1. Dans un nouveau terminal, exÃ©cutez:")
    print("   tensorboard --logdir artifacts/tensorboard --port 6006")
    print("2. Ouvrez: http://localhost:6006")
    print("3. Les mÃ©triques disponibles:")
    print("   - Dataset: samples, features, classes")
    print("   - Training: temps d'entraÃ®nement")
    print("   - Performance: accuracy")
    print("   - Par classe: precision, recall, f1-score")
    print("   - Features: histogrammes des distributions")
    print("   - Confusion_Matrix: matrice de confusion")
    
    # Chemin absolu pour TensorBoard
    abs_tensorboard_path = os.path.abspath(tensorboard_path)
    print(f"\nğŸ“ Chemin absolu TensorBoard: {abs_tensorboard_path}")
else:
    print("âš ï¸ TensorBoard non disponible")
    print("   Pour l'activer: pip install torch tensorboard matplotlib")

print("="*60)