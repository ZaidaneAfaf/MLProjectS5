# train.py
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import joblib
import os
import json
import psutil
import threading
import time
from datetime import datetime
from torch.utils.tensorboard import SummaryWriter
import shutil

# ğŸ”¹ RÃ©pertoire de base (oÃ¹ est le script)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ğŸ”¹ Chemins absolus pour les donnÃ©es et modÃ¨les
DATA_PATH = os.path.join(BASE_DIR, "..", "data", "Iris.csv")
MODELS_DIR = os.path.join(BASE_DIR, "..", "models")
LOGS_DIR = os.path.join(BASE_DIR, "..", "logs", "tensorboard")
os.makedirs(MODELS_DIR, exist_ok=True)
os.makedirs(LOGS_DIR, exist_ok=True)

# ğŸ”¹ NETTOYAGE DES LOGS EXISTANTS
if os.path.exists(LOGS_DIR):
    shutil.rmtree(LOGS_DIR)
os.makedirs(LOGS_DIR, exist_ok=True)

# ğŸ“Š Classe pour monitorer CPU/RAM
class ResourceMonitor:
    def __init__(self, model_name):
        self.model_name = model_name
        self.cpu_usage = []
        self.memory_usage = []
        self.memory_mb = []
        self.monitoring = False
        self.thread = None
        self.start_time = None
        self.process = psutil.Process()
        
    def _monitor(self):
        while self.monitoring:
            try:
                cpu = psutil.cpu_percent(interval=0.1)
                mem = psutil.virtual_memory().percent
                mem_mb = self.process.memory_info().rss / (1024 * 1024 * 1024)  # GB
                
                self.cpu_usage.append(cpu)
                self.memory_usage.append(mem)
                self.memory_mb.append(mem_mb)
                
                time.sleep(0.5)
            except:
                pass
    
    def start(self):
        self.monitoring = True
        self.start_time = time.time()
        self.thread = threading.Thread(target=self._monitor, daemon=True)
        self.thread.start()
        print(f"ğŸ” {self.model_name.upper()}: Monitoring dÃ©marrÃ©...")
    
    def stop(self):
        self.monitoring = False
        if self.thread:
            self.thread.join(timeout=2)
        duration = time.time() - self.start_time
        
        # Affichage console
        print(f"\nğŸ“Š RÃ‰SUMÃ‰ RESSOURCES - {self.model_name.upper()}")
        print(f"â±ï¸  DurÃ©e monitoring: {duration:.0f} secondes")
        print(f"ğŸ’» CPU moyen: {sum(self.cpu_usage)/len(self.cpu_usage):.1f}% (max: {max(self.cpu_usage):.1f}%)")
        print(f"ğŸ§  MÃ©moire moyenne: {sum(self.memory_usage)/len(self.memory_usage):.1f}% (max: {max(self.memory_usage):.1f}%)")
        print(f"ğŸ’¾ MÃ©moire utilisÃ©e: {sum(self.memory_mb)/len(self.memory_mb):.1f} GB")
        
        return {
            'duration': duration,
            'cpu_mean': sum(self.cpu_usage)/len(self.cpu_usage) if self.cpu_usage else 0,
            'cpu_max': max(self.cpu_usage) if self.cpu_usage else 0,
            'cpu_values': self.cpu_usage,
            'mem_mean': sum(self.memory_usage)/len(self.memory_usage) if self.memory_usage else 0,
            'mem_max': max(self.memory_usage) if self.memory_usage else 0,
            'mem_values': self.memory_usage,
            'mem_gb': sum(self.memory_mb)/len(self.memory_mb) if self.memory_mb else 0
        }

# 1. Chargement des donnÃ©es
iris = pd.read_csv(DATA_PATH)

print("ğŸ“Š Dataset original:")
print(f"Shape: {iris.shape}")
print(f"Colonnes: {list(iris.columns)}")

# 2. SÃ©lection des colonnes
feature_columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']
target_column = 'Species'

missing_cols = [col for col in feature_columns + [target_column] if col not in iris.columns]
if missing_cols:
    print(f"âŒ Colonnes manquantes: {missing_cols}")
    print("Colonnes disponibles:", list(iris.columns))
    exit(1)

# 3. Features et target
X = iris[feature_columns].copy()
y = iris[target_column].copy()

print(f"\nâœ… Features sÃ©lectionnÃ©es: {X.shape}")
print(f"Features: {list(X.columns)}")
print(f"Target: {y.name}")
print(f"Classes uniques: {y.unique()}")

# 4. Split train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# 5. Sauvegarde du X_test et y_test
TEST_DATA_PATH = os.path.join(BASE_DIR, "..", "data", "iris_test.json")

test_data = {
    "X": X_test.values.tolist(),
    "y": y_test.tolist()
}

with open(TEST_DATA_PATH, "w", encoding="utf-8") as f:
    json.dump(test_data, f, indent=4, ensure_ascii=False)

print(f"ğŸ’¾ Jeu de test sauvegardÃ© dans : {TEST_DATA_PATH}")

# 6. DÃ©finition des modÃ¨les
models = {
    "svm": SVC(probability=True, random_state=42),
    "random_forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "logistic_regression": LogisticRegression(max_iter=200, random_state=42, multi_class="multinomial")
}

results = {}
resources_stats = {}

# TensorBoard Writer
writer = SummaryWriter(log_dir=LOGS_DIR)

print("\n" + "="*70)
print("ğŸ’» CONSOMMATION CPU/RAM PAR MODÃˆLE")
print("="*70)

# 7. EntraÃ®nement et Ã©valuation avec monitoring
for idx, (name, model) in enumerate(models.items()):
    print(f"\nğŸš€ EntraÃ®nement du modÃ¨le: {name}")
    
    # DÃ©marrer le monitoring
    monitor = ResourceMonitor(name)
    monitor.start()
    
    # EntraÃ®nement
    model.fit(X_train, y_train)
    
    # ArrÃªter le monitoring
    stats = monitor.stop()
    resources_stats[name] = stats
    
    # Ã‰valuation
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy
    print(f"âœ… {name} Accuracy: {accuracy:.3f}")
    
    # ğŸ“Š CORRECTION: Ã‰criture dans TensorBoard avec step diffÃ©rent pour chaque modÃ¨le
    # RÃ©sumÃ© texte pour chaque modÃ¨le
    text_summary = f"""
# ğŸ”¹ {name.upper()}

**Accuracy:** {accuracy:.3f}  
**CPU moyen:** {stats['cpu_mean']:.1f}% (max: {stats['cpu_max']:.1f}%)  
**RAM moyenne:** {stats['mem_mean']:.1f}% (max: {stats['mem_max']:.1f}%)  
**MÃ©moire utilisÃ©e:** {stats['mem_gb']:.3f} GB  
**DurÃ©e:** {stats['duration']:.1f}s

---
"""
    # IMPORTANT: Utiliser des steps diffÃ©rents (idx) pour chaque modÃ¨le
    writer.add_text(f'Performances_Modeles/{name.upper()}', text_summary, idx)
    
    # MÃ©triques scalaires avec steps
    writer.add_scalar(f'Accuracy/{name}', accuracy, idx)
    writer.add_scalar(f'CPU_Moyen/{name}', stats['cpu_mean'], idx)
    writer.add_scalar(f'CPU_Max/{name}', stats['cpu_max'], idx)
    writer.add_scalar(f'RAM_Moyenne/{name}', stats['mem_mean'], idx)
    writer.add_scalar(f'RAM_Max/{name}', stats['mem_max'], idx)
    writer.add_scalar(f'Memoire_GB/{name}', stats['mem_gb'], idx)
    writer.add_scalar(f'Duree_secondes/{name}', stats['duration'], idx)
    
    # Test rapide
    test_data_sample = X_test.iloc[0:1]
    pred = model.predict(test_data_sample)[0]
    proba = model.predict_proba(test_data_sample).max()

    print(f"ğŸ§ª Test {name}:")
    print(f"Input: {test_data_sample.values}")
    print(f"PrÃ©diction: {pred}, Confiance: {proba:.3f}")

    # Sauvegarde du modÃ¨le
    joblib.dump(model, os.path.join(MODELS_DIR, f"{name}_iris_model.pkl"))
    print(f"ğŸ’¾ ModÃ¨le sauvegardÃ©: {os.path.join(MODELS_DIR, f'{name}_iris_model.pkl')}")

# ğŸ“Š RÃ‰SUMÃ‰ GLOBAL dans TensorBoard
print("\nğŸ“ CrÃ©ation du rÃ©sumÃ© global pour TensorBoard...")

global_summary = """
# ğŸ“Š RÃ‰SUMÃ‰ FINAL DES PERFORMANCES

======================================================================

"""

for name in models.keys():
    stats = resources_stats[name]
    acc = results[name]
    global_summary += f"""
## ğŸ”¹ {name.upper()}

- **âœ… Accuracy:** {acc:.3f}
- **ğŸ’» CPU moyen:** {stats['cpu_mean']:.1f}% (max: {stats['cpu_max']:.1f}%)
- **ğŸ§  RAM moyenne:** {stats['mem_mean']:.1f}% (max: {stats['mem_max']:.1f}%)
- **ğŸ’¾ MÃ©moire:** {stats['mem_gb']:.3f} GB
- **â±ï¸ DurÃ©e:** {stats['duration']:.1f}s

---

"""

# IMPORTANT: Utiliser step 0 pour le rÃ©sumÃ© global
writer.add_text('00_RESUME_GLOBAL_PERFORMANCES', global_summary, 0)

# Tableau comparatif
comparison_table = """
# ğŸ“Š TABLEAU COMPARATIF

| ModÃ¨le | Accuracy | CPU Moyen | RAM Moyenne | MÃ©moire (GB) | DurÃ©e (s) |
|--------|----------|-----------|-------------|--------------|-----------|
"""

for name in models.keys():
    stats = resources_stats[name]
    acc = results[name]
    comparison_table += f"| {name.upper()} | {acc:.3f} | {stats['cpu_mean']:.1f}% | {stats['mem_mean']:.1f}% | {stats['mem_gb']:.3f} | {stats['duration']:.1f} |\n"

writer.add_text('01_TABLEAU_COMPARATIF', comparison_table, 0)

# Comparaisons scalaires groupÃ©es
cpu_dict = {name: resources_stats[name]['cpu_mean'] for name in models.keys()}
ram_dict = {name: resources_stats[name]['mem_mean'] for name in models.keys()}
acc_dict = {name: results[name] for name in models.keys()}
mem_dict = {name: resources_stats[name]['mem_gb'] for name in models.keys()}
dur_dict = {name: resources_stats[name]['duration'] for name in models.keys()}

writer.add_scalars('Comparaison/CPU_Moyen', cpu_dict, 0)
writer.add_scalars('Comparaison/RAM_Moyenne', ram_dict, 0)
writer.add_scalars('Comparaison/Accuracy', acc_dict, 0)
writer.add_scalars('Comparaison/Memoire_GB', mem_dict, 0)
writer.add_scalars('Comparaison/Duree', dur_dict, 0)

# IMPORTANT: Flush et fermer
writer.flush()
writer.close()

print("âœ… DonnÃ©es Ã©crites dans TensorBoard avec succÃ¨s!")

# 8. Sauvegarder infos features
feature_info = {
    'feature_names': feature_columns,
    'n_features': len(feature_columns),
    'models': list(models.keys())
}
joblib.dump(feature_info, os.path.join(MODELS_DIR, "feature_info.pkl"))
print("\nğŸ’¾ Info features sauvegardÃ©es: ", os.path.join(MODELS_DIR, "feature_info.pkl"))

print("\n" + "="*70)
print("ğŸ“Š RÃ‰SUMÃ‰ FINAL DES PERFORMANCES")
print("="*70)
for name, acc in results.items():
    stats = resources_stats[name]
    print(f"\nğŸ”¹ {name.upper()}")
    print(f"  âœ… Accuracy: {acc:.3f}")
    print(f"  ğŸ’» CPU moyen: {stats['cpu_mean']:.1f}% (max: {stats['cpu_max']:.1f}%)")
    print(f"  ğŸ§  RAM moyenne: {stats['mem_mean']:.1f}% (max: {stats['mem_max']:.1f}%)")
    print(f"  ğŸ’¾ MÃ©moire: {stats['mem_gb']:.3f} GB")
    print(f"  â±ï¸  DurÃ©e: {stats['duration']:.1f}s")

print("\n" + "="*70)
print(f"ğŸ“Š TensorBoard logs sauvegardÃ©s dans: {LOGS_DIR}")
print("ğŸš€ Pour visualiser: tensorboard --logdir=" + LOGS_DIR)
print("\nğŸ“‹ GUIDE TENSORBOARD - OÃ¹ trouver les informations:")
print("  1. ğŸ”  Onglet TEXT:")
print("     - '00_RESUME_GLOBAL_PERFORMANCES' : RÃ©sumÃ© complet de tous les modÃ¨les")
print("     - '01_TABLEAU_COMPARATIF' : Tableau comparatif")
print("     - 'Performances_Modeles/' : DÃ©tails par modÃ¨le")
print("  2. ğŸ“ˆ Onglet SCALARS:")
print("     - 'Accuracy/' : PrÃ©cision par modÃ¨le")
print("     - 'CPU_Moyen/' et 'CPU_Max/' : Consommation CPU")
print("     - 'RAM_Moyenne/' et 'RAM_Max/' : Utilisation mÃ©moire")
print("     - 'Comparaison/' : Graphiques comparatifs entre modÃ¨les")
print("  3. ğŸ” Astuce: Utilisez la barre de recherche pour filtrer")
print("="*70)